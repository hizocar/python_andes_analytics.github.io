{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Missing Data in a Dataset"
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "f0ac540f-8500-4f38-ac44-afccec47f0b7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying Missing Data\n",
        "\n",
        "The first step in dealing with missing data is to identify its presence and location within your dataset. This can be done using various methods, depending on the tools and programming language you are using. In Python, for instance, you can use libraries like Pandas to easily find missing values.\n",
        "\n",
        "```python\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "missing_values = df.isnull()\n",
        "\n",
        "print(missing_values.sum())\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "This code will give you a count of missing values in each column of your DataFrame."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "feec03b8-223c-46af-829d-c1ed03ad0573"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "Once you've identified the missing data, the next step is to decide how to handle it. The approach depends on the nature of your data and the amount of missing information. Here are some common strategies:\n",
        "\n",
        "\n",
        "### 1. Removing Data\n",
        "\n",
        "- **Drop rows with missing values:** If the dataset is large and the number of rows with missing data is small, you might consider removing these rows.\n",
        "\n",
        "```python\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "```\n",
        "\n",
        "- **Drop columns with missing values:** If a specific column has a significant number of missing values, it might be better to remove the entire column.\n",
        "\n",
        "```python\n",
        "\n",
        "df.dropna(axis=1, inplace=True)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### 2. Imputing Data\n",
        "\n",
        "- **Mean/Median/Mode Imputation:** Replace missing values with the mean, median, or mode of the column. This is useful for numerical data.\n",
        "\n",
        "```python\n",
        "\n",
        "# For mean imputation\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "\n",
        "# For median imputation\n",
        "\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "\n",
        "# For mode imputation (for categorical data)\n",
        "\n",
        "df.fillna(df.mode().iloc[0], inplace=True)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "- **Custom Imputation:** Use domain knowledge or other algorithms to impute missing values.\n",
        "\n",
        "\n",
        "### 3. Using Algorithms that Support Missing Values\n",
        "\n",
        "- Some machine learning algorithms can handle missing values inherently. For example, decision trees and random forests can handle missing data without imputation."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "90e5845c-0613-4a2b-9709-22e3c5f2e750"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset with missing values\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', None],\n",
        "\n",
        "        'Age': [25, None, 30, 22],\n",
        "\n",
        "        'Salary': [70000, 80000, None, 40000]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "da126378-9f31-4729-b5f2-ff79e8d5106d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying missing values\n",
        "\n",
        "print(\"Missing values in each column:\")\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "338f2afc-2c88-4223-8203-649fa3670f33"
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing data\n",
        "\n",
        "# Option 1: Removing rows with missing values\n",
        "\n",
        "df_dropped_rows = df.dropna()\n",
        "\n",
        "print(\"DataFrame after dropping rows with missing values:\")\n",
        "\n",
        "print(df_dropped_rows)\n",
        "\n",
        "\n",
        "# Option 2: Imputing missing values\n",
        "\n",
        "# For simplicity, we'll use mean for numerical columns and mode for categorical columns\n",
        "\n",
        "df_imputed = df.copy()\n",
        "\n",
        "df_imputed['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "\n",
        "df_imputed['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
        "\n",
        "df_imputed['Name'].fillna(df['Name'].mode()[0], inplace=True)\n",
        "\n",
        "print(\"\\nDataFrame after imputing missing values:\")\n",
        "\n",
        "print(df_imputed)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "2bb9f7e4-e54c-49d2-b708-990aac881b57"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Outliers in a Dataset"
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "4fb73d8f-0ceb-4316-aec1-a49d6c62a3e7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding and Handling Outliers\n",
        "\n",
        "Outliers are data points that differ significantly from other observations. They can occur due to variability in the measurement or may indicate experimental errors. Handling outliers is crucial as they can lead to misleading representations and affect the results of data analysis.\n",
        "\n",
        "\n",
        "### Steps to Handle Outliers:\n",
        "\n",
        "1. **Visualizing Data**: Using plots like boxplots to identify outliers.\n",
        "\n",
        "2. **Identifying Outliers**: Determining which data points are considered outliers.\n",
        "\n",
        "3. **Removing Outliers**: Deciding on a strategy to handle outliers, often by removing them.\n",
        "\n",
        "\n",
        "We will demonstrate these steps using a dataset with more than 50 rows, analyze it with a boxplot, identify outliers, and then remove them."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "1b40bf11-7009-43db-aa1b-30995cb72007"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Generating a dataset with more than 50 rows\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "data = np.random.normal(100, 20, 60)\n",
        "\n",
        "\n",
        "# Introducing outliers\n",
        "\n",
        "data = np.append(data, [300, 305])\n",
        "\n",
        "\n",
        "# Creating a DataFrame\n",
        "\n",
        "df_outliers = pd.DataFrame(data, columns=['Values'])\n",
        "\n",
        "\n",
        "# Displaying the first few rows\n",
        "\n",
        "print(df_outliers.head())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:35:24.083305+00:00",
          "end_time": "2023-11-19T17:35:24.413019+00:00"
        }
      },
      "id": "265e33c2-a986-4f36-a10b-a490b24b1cd1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data with a boxplot\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.boxplot(df_outliers['Values'])\n",
        "\n",
        "plt.title('Boxplot of Values')\n",
        "\n",
        "plt.ylabel('Value')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# This boxplot will help us identify the outliers visually."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:35:32.265214+00:00",
          "end_time": "2023-11-19T17:35:32.772862+00:00"
        }
      },
      "id": "c65681fa-ffea-4b2f-9f31-f6a058a33822"
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying and removing outliers\n",
        "\n",
        "Q1 = df_outliers['Values'].quantile(0.25)\n",
        "\n",
        "Q3 = df_outliers['Values'].quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "\n",
        "# Defining bounds for outliers\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "\n",
        "# Filtering out the outliers\n",
        "\n",
        "df_filtered = df_outliers[(df_outliers['Values'] >= lower_bound) & (df_outliers['Values'] <= upper_bound)]\n",
        "\n",
        "\n",
        "# Displaying the filtered DataFrame\n",
        "\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "\n",
        "print(df_filtered)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:35:39.551163+00:00",
          "end_time": "2023-11-19T17:35:39.710431+00:00"
        }
      },
      "id": "60e4d9da-3808-404f-a906-01e8bef24683"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting Variables for a Classification Model"
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "578fd304-f348-4012-ace3-ecfc9264a9c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting Variables for Classification Using the Iris Dataset\n",
        "\n",
        "In this section, we will demonstrate how to select variables for a classification model using the Iris dataset. This dataset is a classic in machine learning, featuring measurements of iris flowers and their species. We will explore different techniques to determine which features are most important for classification."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "37b2f8d2-e00c-460d-ae73-40597e351745"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "# Loading the Iris dataset\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X = iris.data\n",
        "\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "\n",
        "print(X[:5, :])\n",
        "\n",
        "print(y[:5])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:40:27.785898+00:00",
          "end_time": "2023-11-19T17:40:28.316399+00:00"
        }
      },
      "id": "d049e9ff-ec86-490e-b05c-754da1380a60"
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection using SelectKBest and Chi-Squared Test\n",
        "\n",
        "# Selecting the top 2 features\n",
        "\n",
        "selector = SelectKBest(score_func=chi2, k=2)\n",
        "\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "\n",
        "# Displaying the selected features\n",
        "\n",
        "print(\"Selected Features:\")\n",
        "\n",
        "print(X_selected[:5, :])\n",
        "\n",
        "\n",
        "# The scores for each feature\n",
        "\n",
        "print(\"Feature Scores:\")\n",
        "\n",
        "print(selector.scores_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:40:34.858952+00:00",
          "end_time": "2023-11-19T17:40:35.016502+00:00"
        }
      },
      "id": "9585a083-02b7-408d-8388-d37b5c570781"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection Using Random Forest on the Wine Dataset\n",
        "\n",
        "Another popular technique for feature selection is using a Random Forest classifier. This method is particularly useful for understanding feature importance in classification tasks. We will use the Wine dataset, another classic dataset in machine learning, to demonstrate this technique."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "22b4b3c8-2ca7-4226-8682-aefe017b6a6c"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Loading the Wine dataset\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "X_wine = wine.data\n",
        "\n",
        "y_wine = wine.target\n",
        "\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "\n",
        "print(X_wine[:5, :])\n",
        "\n",
        "print(y_wine[:5])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:41:54.235874+00:00",
          "end_time": "2023-11-19T17:41:54.407421+00:00"
        }
      },
      "id": "0234a7c6-626f-4121-9a7c-2177e03246b6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection using Random Forest\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "rf.fit(X_wine, y_wine)\n",
        "\n",
        "\n",
        "# Getting feature importances\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "\n",
        "# Sorting the feature importances in descending order\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "# Displaying the feature importances\n",
        "\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X_wine.shape[1]):\n",
        "\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:41:56.742804+00:00",
          "end_time": "2023-11-19T17:41:56.984506+00:00"
        }
      },
      "id": "5fe87db9-8f64-49d9-be4e-df4ffcf22962"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting feature importances\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.title(\"Feature Importances in the Wine Dataset\")\n",
        "\n",
        "plt.bar(range(X_wine.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
        "\n",
        "plt.xticks(range(X_wine.shape[1]), wine.feature_names, rotation=45)\n",
        "\n",
        "plt.xlim([-1, X_wine.shape[1]])\n",
        "\n",
        "plt.ylabel('Importance')\n",
        "\n",
        "plt.xlabel('Features')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# This plot will help us visually assess which features are most important."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:42:42.126446+00:00",
          "end_time": "2023-11-19T17:42:42.529116+00:00"
        }
      },
      "id": "4af74d9e-4249-46d9-a8f9-6b5431036458"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion on Feature Selection for the Wine Dataset\n",
        "\n",
        "Based on the feature importance rankings and the visual representation, we can conclude which features are most significant for the classification model. Generally, features with higher importance scores are more influential in predicting the target variable. In this case, we would select the top-ranking features as they have the highest impact on the model's performance."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "51c8dcc6-3c7b-4bcf-9b22-444ecd716428"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection Using Principal Component Analysis (PCA) on the Breast Cancer Dataset\n",
        "\n",
        "Principal Component Analysis (PCA) is a technique used for dimensionality reduction, which can also be helpful in feature selection. It transforms the data into a new set of variables, the principal components, which are orthogonal and uncorrelated. We will use the Breast Cancer dataset to demonstrate this technique."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "32ae5a35-3f27-4e81-8265-6e58efc86db7"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Loading the Breast Cancer dataset\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "\n",
        "X_cancer = breast_cancer.data\n",
        "\n",
        "y_cancer = breast_cancer.target\n",
        "\n",
        "\n",
        "# Creating a DataFrame for better visualization\n",
        "\n",
        "df_cancer = pd.DataFrame(X_cancer, columns=breast_cancer.feature_names)\n",
        "\n",
        "df_cancer['target'] = y_cancer\n",
        "\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "\n",
        "df_cancer.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:44:29.035608+00:00",
          "end_time": "2023-11-19T17:44:29.314277+00:00"
        },
        "datalink": {
          "47118f31-ada2-4d7a-b58c-269faef38694": {
            "dataframe_info": {
              "default_index_used": true,
              "orig_size_bytes": 1280,
              "orig_num_rows": 5,
              "orig_num_cols": 31,
              "truncated_string_columns": [],
              "truncated_size_bytes": 1280,
              "truncated_num_rows": 5,
              "truncated_num_cols": 31
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "47118f31-ada2-4d7a-b58c-269faef38694",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-11-19T17:44:29.138356",
            "variable_name": "unk_dataframe_d61dc31670c341e293b37f9986c2190a",
            "user_variable_name": null
          }
        },
        "dx": {
          "views": [],
          "fieldMetadata": {},
          "simpleTable": true,
          "updated": 1700415874752
        }
      },
      "id": "988bef3d-8758-4fc2-b96d-57910aa07794"
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "X_pca = pca.fit_transform(X_cancer)\n",
        "\n",
        "\n",
        "# Creating a DataFrame for the PCA results\n",
        "\n",
        "df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
        "\n",
        "df_pca['target'] = y_cancer\n",
        "\n",
        "\n",
        "# Displaying the first few rows of the PCA results\n",
        "\n",
        "df_pca.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:44:44.364596+00:00",
          "end_time": "2023-11-19T17:44:44.822161+00:00"
        },
        "datalink": {
          "28f3a508-b094-4081-a53a-2179eab843df": {
            "dataframe_info": {
              "default_index_used": true,
              "orig_size_bytes": 160,
              "orig_num_rows": 5,
              "orig_num_cols": 3,
              "truncated_string_columns": [],
              "truncated_size_bytes": 160,
              "truncated_num_rows": 5,
              "truncated_num_cols": 3
            },
            "dx_settings": {
              "LOG_LEVEL": 30,
              "DEV_MODE": false,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MAX_COLUMNS": 100,
              "HTML_TABLE_SCHEMA": false,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "SAMPLING_FACTOR": 0.1,
              "DISPLAY_MODE": "simple",
              "SAMPLING_METHOD": "random",
              "COLUMN_SAMPLING_METHOD": "outer",
              "ROW_SAMPLING_METHOD": "random",
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "FLATTEN_INDEX_VALUES": false,
              "FLATTEN_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false,
              "STRINGIFY_COLUMN_VALUES": true,
              "ENABLE_DATALINK": true,
              "ENABLE_ASSIGNMENT": true,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "DB_LOCATION": ":memory:",
              "GENERATE_DEX_METADATA": false,
              "ALLOW_NOTEABLE_ATTRS": true
            },
            "display_id": "28f3a508-b094-4081-a53a-2179eab843df",
            "applied_filters": [],
            "sample_history": [],
            "sampling_time": "2023-11-19T17:44:44.588641",
            "variable_name": "unk_dataframe_2fc1d8a7ab874e10823d5a628fac9c41",
            "user_variable_name": null
          }
        },
        "dx": {
          "views": [],
          "fieldMetadata": {},
          "simpleTable": true,
          "updated": 1700415886966
        }
      },
      "id": "85927d56-7e85-4b35-9fc0-f56be2783dd6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the PCA results\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Plotting the PCA components\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='target', data=df_pca, palette='Set1')\n",
        "\n",
        "plt.title('PCA of Breast Cancer Dataset')\n",
        "\n",
        "plt.xlabel('Principal Component 1')\n",
        "\n",
        "plt.ylabel('Principal Component 2')\n",
        "\n",
        "plt.legend(title='Target')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# This plot will help us understand the distribution of the data in the new feature space created by PCA."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "start_time": "2023-11-19T17:44:57.515602+00:00",
          "end_time": "2023-11-19T17:44:57.967923+00:00"
        }
      },
      "id": "e22adc56-fd9d-464e-8b9e-4b55841adaca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion on Feature Selection with PCA\n",
        "\n",
        "After applying PCA to the Breast Cancer dataset, we can observe how the data is distributed across the principal components. PCA helps in reducing the dimensionality of the dataset while retaining the most significant features. In this case, we transformed the data into two principal components. These components can be used for further analysis or in building classification models, as they encapsulate the most variance of the dataset."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "7c713894-f974-4c73-a14f-2acba8a7f1b8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student Exercise: Preprocessing and Model Selection with Cardio Dataset\n",
        "\n",
        "Now, it's your turn to apply the techniques we've discussed using the `cardio.csv` dataset. Your tasks are as follows:\n",
        "\n",
        "\n",
        "1. **Handle Missing Data**: Either remove missing values or impute them based on the techniques discussed.\n",
        "\n",
        "2. **Eliminate Outliers**: Identify and remove outliers from each column.\n",
        "\n",
        "3. **Feature Selection**: Choose the best variables for the model using the methods we've explored.\n",
        "\n",
        "4. **Model Building and Comparison**: Build models using KNN (K-Nearest Neighbors) and Logistic Regression. Compare the performance of these models with the metrics obtained in the previous class.\n",
        "\n",
        "\n",
        "This exercise will help you solidify your understanding of data preprocessing and model selection. Good luck!"
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "8f03824f-756c-4c02-a223-3a601efcff1d"
    }
  ],
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "fcfd4547-b045-5a52-babe-43850185cd65",
        "openai_ephemeral_user_id": "2892c03b-49ed-5308-9944-0b98813bf040",
        "openai_subdivision1_iso_code": "CL-RM"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "identifier": "legacy",
      "language": "python",
      "language_version": "3.9",
      "name": "python3"
    },
    "selected_hardware_size": "small",
    "noteable": {
      "last_delta_id": "fcfb0355-c03a-4f49-bc1f-626d64ff675a"
    },
    "nteract": {
      "version": "noteable@2.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}